modal run scripts/003-chat-with-pdf-vision.py

# â¯ ./scripts/003-chat-with-pdf-vision.sh
# âœ“ Initialized. View run at https://modal.com/apps/wattai/main/ap-XXX
# âœ“ Created objects.
# â”œâ”€â”€ ğŸ”¨ Created mount /home/wattai/dev/pg-modal/scripts/003-chat-with-pdf-vision.py
# â”œâ”€â”€ ğŸ”¨ Created function convert_pdf_to_images.
# â”œâ”€â”€ ğŸ”¨ Created function download_model.
# â”œâ”€â”€ ğŸ”¨ Created function Model.load_models.
# â”œâ”€â”€ ğŸ”¨ Created function Model.*.
# â”œâ”€â”€ ğŸ”¨ Created function Model.index_pdf.
# â””â”€â”€ ğŸ”¨ Created function Model.respond_to_message.
# Starting a new session with id f13178c3-06f5-4e9c-85e6-bad75707515f
# Indexing PDF from https://arxiv.org/pdf/1706.03762
# `Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
# Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.08s/it]
# Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.07it/s]
# QUESTION: What is this document about?
# This document is about the Transformer model, a type of neural network architecture that has been proposed as a solution to the challenge of 
# sequence transduction tasks. The Transformer model is designed to be simple, efficient, and parallelizable, and it has shown superior 
# performance compared to other models on various tasks.
# Stopping app - local entrypoint completed.
# Runner terminated.
# âœ“ App completed. View run at https://modal.com/apps/wattai/main/ap-XXX
